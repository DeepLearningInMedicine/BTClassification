# Brain Tumor Segmentation
# Script for Preprocessing
# Author: Qixun Qu
# Create on: 2017/09/10
# Modify on: 2017/09/17

'''

Class BTSPreprocess

-1- Correct bias field via N4BiasFieldCorrection.
-2- Intensity normalization on each volume.
-3- Merge four volumes (Flair, T1, T1c and T2) into one volume
    and remove surrounding backgrounds to keep minimum volume.


Pipline of Preprocessing:

           Generate All Paths from Input Folder
      Generate Folders for Template and Output Files 
                            |
    --------------------------------------------------
    |      |      |      |      |      |      |      |
  N4ITK  N4ITK  N4ITK  N4ITK  N4ITK  N4ITK  N4ITK  N4ITK  <=== Multi-process of
    |      |      |      |      |      |      |      |         N4BiasFieldCorrection
    --------------------------------------------------
                            |
              Save Outputs in Template Folder
                            |
                -------------------------
                |       |       |       |
              Flair    T1      T1c     T2  <=== Multi-process of
                |       |       |       |       Intensity Normalization
                -------------------------
                            |
              Save Outputs in Template Folder
                            |
    --------------------------------------------------
    |      |      |      |      |      |      |      |
  Merge  Merge  Merge  Merge  Merge  Merge  Merge  Merge  <=== Multi-process of
    &      &      &      &      &      &      &      &         Merge four types volumes into
  Save   Save   Save   Save   Save   Save   Save   Save        one volume, remove surrounding
    |      |      |      |      |      |      |      |         backgrounds and save outputs
    --------------------------------------------------
                            |
              Save Outputs in Output Folder
                 Delete Template Folder

'''



import numpy as np
from skimage import io
from bts_settings import *
import os, shutil, subprocess
from multiprocessing import Pool, cpu_count
from nipype.interfaces.ants.segmentation import N4BiasFieldCorrection



# Helper function to do multiprocessing of
# BTSPreprocess._bias_field_correction
def unwrap_bias_field_correction(arg, **kwarg):
    return BTSPreprocess._bias_field_correction(*arg, **kwarg)


# Helper function to do multiprocessing of
# BTSPreprocess._intensity_normalization
def unwrap_intensity_normalization(arg, **kwarg):
    return BTSPreprocess._intensity_normalization(*arg, **kwarg)


# Helper function to do multiprocessing of
# BTSPreprocess._merge_to_one_volume
def unwrap_merge_to_one_volume(arg, **kwarg):
    return BTSPreprocess._merge_to_one_volume(*arg, **kwarg)


class BTSPreprocess():

    def __init__(self, input_dir, output_dir, temp_dir="temp"):

        '''__INIT__

            Initialization of class BTSPreprocess, and finish
            preprocessing of all brain volumes.

            The structure as follows:
            - Create folders to keep template files and save 
              output files which has been preprocessed.
            - Multiprocess of function to correct bias field.
            - Multiprocess of function to normalize intensity.
            - Multiprocess of function to merge and save output.
            - Delete all template files.

            Inputs:

            - input_dir: path of the directory which
                         keeps original volumes
            - output_dir: path of the directory which
                          outputs will be saved in
            - temp_dir: path of the directory which
                        keeps template files during the
                        preprocessing, default is "temp" 

        '''

        # Serial numbers of patients generated by bts_reorganize.py
        self.volume_no = os.listdir(input_dir)

        # Output folder of mask volumes
        self.mask_folder = os.path.join(output_dir, "Mask")
        # Output folder of ensemble volumes
        self.full_folder = os.path.join(output_dir, "Full")

        self._create_folders(temp_dir)
        self._bias_field_correction_multi(input_dir, temp_dir)
        self._intensity_normalization_multi(temp_dir)
        self._merge_to_one_volume_multi(input_dir, temp_dir)

        # Delete template folder and all files in it
        shutil.rmtree(temp_dir)

        return


    def _create_folders(self, temp_dir):

        '''_CREATE_FOLDERS

            Create folders for template files and outputs.
            All folders are as below.

            Folder for template files:
            ----- temp_dir (default is "temp")
              |----- Flair
              |----- T1
              |----- T1c
              |----- T2

            Folders for outputs:
            ----- self.output_dir
              |----- Full
              |----- Mask

            Input:

            - temp_dir: path of the directory which
                        keeps template files during the
                        preprocessing, default is "temp"
            
            The other two arguments, self.mask_folder and
            self.full_folder has already assigned while
            the instance is initialized.

        '''

        if not os.path.isdir(temp_dir):
            os.makedirs(temp_dir)
        
        for name in VOLUME_NAMES:
            sub_temp_dir = os.path.join(temp_dir, name)
            if not os.path.isdir(sub_temp_dir):
                os.makedirs(sub_temp_dir)

        if not os.path.isdir(self.mask_folder):
            os.makedirs(self.mask_folder)        

        if not os.path.isdir(self.full_folder):
            os.makedirs(self.full_folder)
        
        return


    def _bias_field_correction_multi(self, input_dir, temp_dir):

        '''_BIAS_FIELD_CORRECTION_MULTI

            Main function of bias field correctgion to map tasks
            on different cpus to accelerate processing speed.
            The number of subprocesses equals to the number of cpus.

            - Generate paths of all original volumes and
              paths of template volumes that will be corrected.
            - Map pairs of paths (original path and template path)
              to function BTSPreprocess._bias_field_correction.

            Inputs:

            - input_dir: path of the directory which
                         keeps original volumes
            - temp_dir: path of the directory which
                        keeps template files during the
                        preprocessing, default is "temp"

        '''

        orig_volumes_path = []  # paths of original volumes
        temp_volumes_path = []  # paths of template volumes
        for name in VOLUME_NAMES:
            for vno in self.volume_no:
                orig = os.path.join(input_dir, vno, name + ".mha")
                temp = os.path.join(temp_dir, name, vno + ".mha")
                orig_volumes_path.append(orig)
                temp_volumes_path.append(temp)

        print("Stage 1: Bias Field Correction\n")
        paras = zip([self] * len(orig_volumes_path),
                    orig_volumes_path,
                    temp_volumes_path)
        pool = Pool(processes=cpu_count())
        pool.map(unwrap_bias_field_correction, paras)

        return


    def _bias_field_correction(self, orig_path, temp_path):

        '''_BIAS_FIELD_CORRECTION

            Apply N4BiasFieldCorrection methos on a volume
            and save the output into template folder.
            Settings can be found in bts_settings.py.

            Original paper can be found here:
            https://www.ncbi.nlm.nih.gov/pubmed/20378467

            Inputs:

            - orig_path: path for original volume
            - temp_path: path for template volume which is
                         the output of bias field correction

            --- NOTE ---

            This function is only tested to deal with .mha files
            in Windows. It is necessary to install ANTs first.
            Download ANTs 2.1 for Windows from this link:
            https://github.com/ANTsX/ANTs/releases.
            Extract files in to folder, and add this folder's path
            into system path.

        '''

        print("N4ITK on: " + orig_path)
        n4 = N4BiasFieldCorrection()
        
        n4.inputs.input_image = orig_path
        n4.inputs.output_image = temp_path

        n4.inputs.dimension = N4_DIMENSION
        n4.inputs.n_iterations = N4_ITERATION
        n4.inputs.shrink_factor = N4_SHRINK_FACTOR
        n4.inputs.convergence_threshold = N4_THRESHOLD
        n4.inputs.bspline_fitting_distance = N4_BSPLINE

        # Run command line with information printing
        # subprocess.call(n4.cmdline.split(" "))
        
        # Run command line silently
        devnull = open(os.devnull, 'w')
        subprocess.call(n4.cmdline.split(" "), stdout=devnull, stderr=devnull)

        return


    def _intensity_normalization_multi(self, temp_dir):

        '''_INTENSITY_NORMALIZATION_MULTI

            Main function of intensity normalization to map tasks
            on different cpus to accelerate processing speed.
            The number of subprocesses equals to the number of cpus.

            Input:

            - temp_dir: path of the template directory that outputs
                        of bias field correction have been saved in

        '''

        print("Stage 2: Intensity Normalization\n")
        paras = zip([self]*len(VOLUME_NAMES),
                    [temp_dir]*len(VOLUME_NAMES),
                    VOLUME_NAMES)
        pool = Pool(processes=cpu_count())
        pool.map(unwrap_intensity_normalization, paras)

        return


    def _intensity_normalization(self, temp_dir, target):

        '''_INTENSITY_NORMALIZATION

            Apply intensity normalization on each type of volumes.
            (There are four types volumes: Flair, T1, T1c and T2.)
            Compute landmarks for Flair, T1, T1c and T2 respectively.
            Obtain intensities at certain percentiles from each volume.
            Transform each volume intensity according to corresponding
            landmarks.

            Original paper can be found here:
            http://ieeexplore.ieee.org/abstract/document/836373/

            Inputs:

            - temp_dir: path of template folder which keeps the outputs
                        of bias field correction
            - target: types of volume, Flair, T1, T1c or T2

        '''

        landmarks, all_volume_pct = self._get_volume_landmarks(temp_dir, target)
        self._intensity_transform(temp_dir, target, landmarks, all_volume_pct)

        return


    def _get_volume_landmarks(self, temp_dir, target):

        '''_GET_VOLUME_LANDMARKS

            Take Flair volumes as example.
            - Extract values from each volume at centain percentiles,
              PCTS, which is assigned in bts_settings.py.
            - Ensemble volumes' percentile values into one array.
            - Compute the mean percentile values as the landmarks
              of all Flair volumes.

            Inputs:

            - temp_dir: path of template folder which keeps the outputs
                        of bias field correction
            - target: types of volume, Flair, T1, T1c or T2

            Outputs:

            - landmarks: mean percentile values of a certain type volumes
            - all_volume_pct: percentile values of each volume in one type

        '''

        print("Compute landmarks of all " + target + " volumes\n")
        all_volume_pct = []
        for vno in self.volume_no:
            # Load bias-corrected volume
            path = os.path.join(temp_dir, target, vno + ".mha")
            volume = io.imread(path, plugin="simpleitk")

            # Check whether volume's background has the minimum intensity.
            # If not, set the background to the minimum intensity.
            volume_min = np.min(volume)
            if volume_min < 0:
                volume[np.where(volume == 0)] = volume_min
                volume = volume - np.min(volume)

            # Sort voxels by their intensities except background,
            # which makes it easy to compute percentile values.
            volume = volume[np.where(volume > 0)]
            sort = np.sort(volume)
            sort_len = len(sort)

            # Compute percentile values of one volume
            one_volume_pct = []
            for p in PCTS:
                pct_idx = int(np.ceil(p * sort_len)) - 1
                if pct_idx < 0: pct_idx = 0
                one_volume_pct.append(sort[pct_idx])

            # Ensembel all volumes' percentile value into one array.
            all_volume_pct.append(one_volume_pct)

        # Compute mean as landmarks of one certain type volume.
        all_volume_pct = np.array(all_volume_pct)
        landmarks = np.mean(all_volume_pct, axis=0)

        return landmarks, all_volume_pct


    def _intensity_transform(self, temp_dir, target, landmarks, pct):

        '''_INTENSITY_TRANSFORM

            Transfor voxels' intensities according to the landmarks.
            For each volume, there are three classes voxels:
            - 1. voxels have higher intensities than its maximum percentile value;
            - 2. voxels have lower intensities than its minimum percentile value;
            - 3. voxels have proper intensities.
            
            Replace voxels 1 by the maximum value of landmarks.
            Set voxels 2 to background value which is 0.
            For voxels 3, transform intensitied to new percentile values
            as landmarks via interpolation.

            Inputs:

            - temp_dir: path of template folder which keeps the outputs
                        of bias field correction
            - target: types of volume, Flair, T1, T1c or T2
            - landmarks: new percentile values computed from
                         all volumes of a certain type
            - pct: original percentile values of volumes of a certain type

        '''

        print("Transform intensity of all " + target + " volumes\n")
        for i in range(len(self.volume_no)):
            # Load bias-corrected volume
            path = os.path.join(temp_dir, target, self.volume_no[i] + ".mha")
            volume = io.imread(path, plugin="simpleitk")

            # Check whether volume's background has the minimum intensity.
            # If not, set the background to the minimum intensity.
            volume_min = np.min(volume)
            if volume_min < 0:
                volume[np.where(volume == 0)] = volume_min
                volume = volume - np.min(volume)

            # Indices of voxels whose intensities are
            # higher than its own maximum percentile value,
            # regard them as higher-voxels
            higher_idx = np.where(volume >= pct[i, -1])
            # Indices of voxels whose intensities are
            # lower than its own minimum percentile value,
            # regard them as lower-voxels
            lower_idx = np.where(volume < pct[i, 0])
            # Indices of voxels that are not background
            non_bg_idx = np.where(volume > 0)

            # Transform foreground voxels to new intensities
            volume[non_bg_idx] = np.interp(volume[non_bg_idx], pct[i, :], landmarks)
            # Set maximum percentile value of landmarks to higher-voxels
            volume[higher_idx] = landmarks[-1]
            # Set 0 to lower-voxels
            volume[lower_idx] = 0

            # Save transformed volumes into template folder
            np.save(os.path.join(temp_dir, target, self.volume_no[i] + ".npy"), volume)

        print(target + ": Done")

        return


    def _merge_to_one_volume_multi(self, input_dir, temp_dir):

        '''_MERGE_TO_ONE_VOLUME_MULTI

            Main function of merging four types volumes and saving outputs
            to map tasks on different cpus to accelerate processing speed.
            The number of subprocesses equals to the number of cpus.

            Inputs:

            - input_dir: path of the directory which keeps mask volumes
            - temp_dir: path of template folder which keeps the outputs
                        of intensity transformation

        '''

        print("Stage 3: Merge Flair, T1, T1c and T2 into One Volume")
        volume_no_len = len(self.volume_no)
        paras = zip([self] * volume_no_len,
                    [input_dir] * volume_no_len,
                    [temp_dir] * volume_no_len,
                    self.volume_no)
        pool = Pool(processes=cpu_count())
        pool.map(unwrap_merge_to_one_volume, paras)

        return


    def _merge_to_one_volume(self, input_dir, temp_dir, vno):

        '''_MERGE_TO_ONE_VOLUME

            Merge normalized Flair, T1, T1c and T2 volumes of one patient
            to one volume. Remove surrounding backgrounds, and save output
            into output folder as the result of preprocessing.

            Inputs:

            - input_dir: path of the directory which keeps mask volumes
            - temp_dir: path of template folder which keeps the outputs
                        of intensity transformation
            - vno: serial number of volumes, which is also the folder name
                   of one patient's volumes

        '''

        print("NO." + vno + ": Save full volume and mask volume")
        full_volume = np.zeros(FULL_SHAPE)
        for i in range(len(VOLUME_NAMES)):
            # Load intensity-transformed volume
            temp_path = os.path.join(temp_dir, VOLUME_NAMES[i], vno+".npy")
            temp_volume = np.load(temp_path)
            # Normalize the volue
            temp_volume = self._normalization(temp_volume)
            # full_volume[..., 0] <== Flair volume
            # full_volume[..., 1] <== T1 volume
            # full_volume[..., 2] <== T1c volume
            # full_volume[..., 3] <== T2 volume
            full_volume[..., i] = temp_volume

        # Load relevant mask
        mask_path = os.path.join(input_dir, vno, "Mask.mha")
        mask_volume = io.imread(mask_path, plugin="simpleitk")
        
        # Remove surrounding backgrounds from ensemble volume and mask volume
        full_volume, mask_volume = self._keep_minimum_volume(full_volume, mask_volume)

        # Save volume into output folders
        full_volume_path = os.path.join(self.full_folder, vno + ".npy")
        mask_volume_path = os.path.join(self.mask_folder, vno + ".npy")

        np.save(full_volume_path, full_volume)
        np.save(mask_volume_path, mask_volume)

        return


    def _normalization(self, volume):

        '''_NORMALIZATION

            Normalize the input volume by substract its mean
            and diveded by its standard deviation.

            Input:

            - volume: the volume needs to be normalized

            Output:

            - normalized volume

        '''

        return (volume - np.mean(volume)) / np.std(volume)


    def _keep_minimum_volume(self, full, mask):

        '''_KEEP_MINIMUM_VOLUME

            Remove surrounding backgrounds from ensemble volume
            and mask volume to keep the minimum volume.
            Based on input volumes, compute the range of indices
            of three axes, extract sub-volume and return it back.

            Inputs:

            - full: ensemble volume
            - mask: relevant mask volume

            Outputs:

            - new_full: new ensemble volume after being processed
            - new_mask: new mask volume after being processed

        '''

        # Function to extract sub-array from given array
        # according to ranges of indices of three axes
        def sub_array(arr, index_begin, index_end):
            return arr[index_begin[0] : index_end[0],
                       index_begin[1] : index_end[1],
                       index_begin[2] : index_end[2]]


        # Compute background value of volume
        full_sum = np.sum(full, axis=3)
        min_full_sum = np.min(full_sum)

        # Compute range of indices of each axes
        non_bg_index = np.where(full_sum > min_full_sum)
        dims_begin = [np.min(nzi) for nzi in non_bg_index]
        dims_end = [np.max(nzi) + 1 for nzi in non_bg_index]

        # Obtain sub-volumes from input volumes
        new_full = sub_array(full, dims_begin, dims_end)
        new_full = new_full.astype(np.float32)
        new_mask = sub_array(mask, dims_begin, dims_end)

        return new_full, new_mask



if __name__ == "__main__":

    input_dir = "E:\\ms\\data\\HGG"
    output_dir = "E:\\ms\\data\\HGGPre"
    temp_dir = "HGGTemp"
    BTSPreprocess(input_dir, output_dir, temp_dir)

    input_dir = "E:\\ms\\data\\LGG"
    output_dir = "E:\\ms\\data\\LGGPre"
    temp_dir = "LGGTemp"
    BTSPreprocess(input_dir, output_dir, temp_dir)
